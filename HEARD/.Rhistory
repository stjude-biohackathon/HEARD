BiocManager::install("qPLEXanalyzer")
quit()
BiocManager::install("MutationalPatterns")
BiocManager::install("BSgenome")
quit()
BiocManager::install("BSgenome")
quit()
# raw datasets with filters applied for mutation count
sbs_filt_500 <- filter_mut_sig(sbs_sigs,hrd_scores,500)
library(klaR)
library(psych)
library(MASS)
library(ggord)
library(devtools)
# loading in libraries to perform data manipulation and visualization
library(dplyr)
library(tibble)
library(ggplot2)
library(ggfortify)
library(gridExtra)
# loading libraries for mutational patterns and BSgenome
library(MutationalPatterns)
library(BSgenome)
library(BSgenome.Hsapiens.UCSC.hg19)
ref_genome <- "BSgenome.Hsapiens.UCSC.hg19"
# loading in some other packages for inspecting the datasets
library(lsa)
# loading in UMAP
library(umap)
# function for filtering extracting and normalizing datasets
filter_mut_sig_norm_hrd <- function (df,hrd,n) {
# pre-filter the HRD scores for samples with lowered purity
hrd <- hrd[hrd$cellularity >= 0.3,]
# subset the dataset according to common samples between HRD and signature dataset
df <- df[,colnames(df) %in% row.names(hrd)]
# do the same for HRD score data frame
hrd <- hrd[row.names(hrd) %in% colnames(df),]
# get the dataset in the correct orientation
df <- as.data.frame(t(df))
# get the names of each sample
sample <- row.names(df)
# get the count of mutational signatures
df <- df %>%
dplyr::rowwise() %>%
dplyr::mutate(
m_count=sum(c_across()))
# extract the m_count
m_count <- as.data.frame(df$m_count)
names(m_count) <- "m_count"
row.names(m_count) <- sample
#  perform the sum-normalization on everything but the sample column & the mut count
df <- df[,1:ncol(df)-1]/df$m_count
# reassign the row names
row.names(df) <- sample
# add the m_count
df <- cbind(df,m_count)
# assign groups
df <- df %>%
rownames_to_column('sample_id') %>%
dplyr::mutate(group=as.factor(ifelse(grepl(pattern = "*.HGG*.", sample_id),"HGG","BT"))) %>%
column_to_rownames('sample_id')
# add the HRD score to the dataset
df$HRD <- hrd$HRDsum
# filter based on mutational signature count
df <- df[df$m_count > n,]
# return the df
return(df)
}
filter_mut_sig_norm <- function (df,hrd,n) {
# pre-filter the HRD scores for samples with lowered purity
#hrd <- hrd[hrd$cellularity >= 0.3,]
# subset the dataset according to common samples between HRD and signature dataset
df <- df[,colnames(df) %in% row.names(hrd)]
# do the same for HRD score data frame
hrd <- hrd[row.names(hrd) %in% colnames(df),]
# get the dataset in the correct orientation
df <- as.data.frame(t(df))
# get the names of each sample
sample <- row.names(df)
# get the count of mutational signatures
df <- df %>%
dplyr::rowwise() %>%
dplyr::mutate(
m_count=sum(c_across()))
# extract the m_count
m_count <- as.data.frame(df$m_count)
names(m_count) <- "m_count"
row.names(m_count) <- sample
#  perform the sum-normalization on everything but the sample column & the mut count
df <- df[,1:ncol(df)-1]/df$m_count
# reassign the row names
row.names(df) <- sample
# add the m_count
df <- cbind(df,m_count)
# assign groups
df <- df %>%
rownames_to_column('sample_id') %>%
dplyr::mutate(group=as.factor(ifelse(grepl(pattern = "*.HGG*.", sample_id),"HGG","BT"))) %>%
column_to_rownames('sample_id')
# add the HRD score to the dataset
df$HRD <- hrd$HRDsum
# filter based on mutational signature count
df <- df[df$m_count > n,]
# return the df
return(df)
}
# function for filtering and extracting datasets
filter_mut_sig <- function (df,hrd,n) {
# pre-filter the HRD scores for samples with lowered purity - only if we are overlaying with HRD score
#hrd <- hrd[hrd$cellularity >= 0.3,]
# pre-filter the dataset according to mappability between HRD and signature dataset
df <- df[,colnames(df) %in% row.names(hrd)]
# do the same for HRD score data frame
hrd <- hrd[row.names(hrd) %in% colnames(df),]
# get the dataset in the correct orientation
df <- as.data.frame(t(df))
# get the names of each sample
sample <- row.names(df)
# get the count of mutational signatures
df <- df %>%
dplyr::rowwise() %>%
dplyr::mutate(
m_count=sum(c_across()))
# reassign the row names
row.names(df) <- sample
# assign groups
df <- df %>%
rownames_to_column('sample_id') %>%
dplyr::mutate(group=as.factor(ifelse(grepl(pattern = "*.HGG*.", sample_id),"HGG","BT"))) %>%
column_to_rownames('sample_id')
# add the HRD score to the dataset
df$HRD <- hrd$HRDsum
# filter based on mutational signature count
df <- df[df$m_count > n,]
# return the df
return(df)
}
filter_mut_sig_hrd <- function (df,hrd,n) {
# pre-filter the HRD scores for samples with lowered purity
hrd <- hrd[hrd$cellularity >= 0.3,]
# pre-filter the dataset according to mappability between HRD and signature dataset
df <- df[,colnames(df) %in% row.names(hrd)]
# do the same for HRD score data frame
hrd <- hrd[row.names(hrd) %in% colnames(df),]
# get the dataset in the correct orientation
df <- as.data.frame(t(df))
# get the names of each sample
sample <- row.names(df)
# get the count of mutational signatures
df <- df %>%
dplyr::rowwise() %>%
dplyr::mutate(
m_count=sum(c_across()))
# reassign the row names
row.names(df) <- sample
# assign groups
df <- df %>%
rownames_to_column('sample_id') %>%
dplyr::mutate(group=as.factor(ifelse(grepl(pattern = "*.HGG*.", sample_id),"HGG","BT"))) %>%
column_to_rownames('sample_id')
# add the HRD score to the dataset
df$HRD <- hrd$HRDsum
# filter based on mutational signature count
df <- df[df$m_count > n,]
# return the df
return(df)
}
# creating a UMAP function for more readable code - HRD
umapper_hrd <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
p <- M3C::umap(t(mat[,names(mat) %!in% c("group","m_count","HRD")]),
labels=anno$HRD,
controlscale=TRUE,
scale=2,
high="red",
low="green",
legendtitle = "HRD Score") +
ggtitle(title)
return(p)
}
# creating a UMAP function for more readable code - group
umapper_group <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
p <- M3C::umap(t(mat[,names(mat) %!in% c("group","m_count","HRD")]),
labels=anno$group,
legendtitle = "Group") +
ggtitle(title)
return(p)
}
# creating a tSNE function for more readable code - HRD
tsnemapper_hrd <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
p <- M3C::tsne(t(mat[,names(mat) %!in% c("group","m_count","HRD")]),
labels=anno$HRD,
controlscale=TRUE,
scale=2,
high="red",
low="green",
legendtitle = "HRD Score") +
ggtitle(title)
return(p)
}
# creating a tSNE function for more readable code - group
tsnemapper_group <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
p <- M3C::tsne(t(mat[,names(mat) %!in% c("group","m_count","HRD")]),
labels=anno$group,
legendtitle = "Group") +
ggtitle(title)
return(p)
}
# creating a PCA plotting function for more readable code
pca_plotter <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
pca_res <- prcomp(mat[,names(mat) %!in% c("group","m_count","HRD")],scale. = TRUE)
p <- autoplot(pca_res,data=anno,colour = 'group', size = "HRD",
label = FALSE,loadings = FALSE, loadings.label = FALSE) +
ggtitle(title)
return(p)
}
pca_plotter_labels <- function (mat,label,title) {
anno <- as.data.frame(mat[,names(mat) %in% c("group","m_count","HRD")])
pca_res <- prcomp(mat[,names(mat) %!in% c("group","m_count","HRD")],scale. = TRUE)
p <- autoplot(pca_res,data=anno,colour = 'group', size = "HRD",
label = FALSE,loadings = FALSE, loadings.label = FALSE) +
ggtitle(title) +
geom_text(label=row.names(mat),fontface = "bold",size=3,position=position_jitter(height = 0.015))
return(p)
}
# creating a negate function for easier subsetting
'%!in%' <- function(x,y){!('%in%'(x,y))}
#
sbs_sigs <- read.table(file = "WGS/HQ_MQ_LQ/output/SBS/205_HGG.SBS96.all",header = TRUE,row.names = 1)
dbs_sigs <- read.table(file = "WGS/HQ_MQ_LQ/output/DBS/205_HGG.DBS78.all",header = TRUE,row.names = 1)
id_sigs <- read.table(file = "WGS/HQ_MQ_LQ/output/ID/205_HGG.ID83.all",header = TRUE,row.names = 1)
hrd_scores <- read.table(file = "HRD_allSamples_WGS_clean.txt",header = TRUE,row.names = 1)
annotations <- read.delim(file = "HRD_allSamples_WGS_sampleinfo_clean.txt",header = TRUE,row.names = 1,sep="\t")
# lets read in the reconstructed
sbs_sig_rec <- read.table(file = "WGS/HQ_MQ_LQ/output/SBS96_fit_reconstructed.txt",header = TRUE,row.names = 1)
dbs_sig_rec <- read.table(file = "WGS/HQ_MQ_LQ/output/DBS78_fit_reconstructed.txt",header = TRUE,row.names = 1)
id_sig_rec <- read.table(file = "WGS/HQ_MQ_LQ/output/ID83_fit_reconstructed.txt",header = TRUE,row.names = 1)
# raw datasets with filters applied for mutation count
sbs_filt_500 <- filter_mut_sig(sbs_sigs,hrd_scores,500)
sbs_filt_1000 <- filter_mut_sig(sbs_sigs,hrd_scores,1000)
sbs_filt_1500 <- filter_mut_sig(sbs_sigs,hrd_scores,1500)
id_filt <- filter_mut_sig(id_sigs,hrd_scores,50)
# create our normalized datasets
sbs_filt_norm_500 <- filter_mut_sig_norm(sbs_sigs,hrd_scores,500)
sbs_filt_norm_1000 <- filter_mut_sig_norm(sbs_sigs,hrd_scores,1000)
sbs_filt_norm_1500 <- filter_mut_sig_norm(sbs_sigs,hrd_scores,1500)
id_filt_norm <- filter_mut_sig_norm(id_sigs,hrd_scores,50)
# raw datasets with filters applied for mutation count + hrd
sbs_filt_500_hrd <- filter_mut_sig_hrd(sbs_sigs,hrd_scores,500)
sbs_filt_1000_hrd <- filter_mut_sig_hrd(sbs_sigs,hrd_scores,1000)
sbs_filt_1500_hrd <- filter_mut_sig_hrd(sbs_sigs,hrd_scores,1500)
id_filt <- filter_mut_sig_hrd(id_sigs,hrd_scores,50)
# create our normalized datasets + hrd
sbs_filt_norm_500_hrd <- filter_mut_sig_norm_hrd(sbs_sigs,hrd_scores,500)
sbs_filt_norm_1000_hrd <- filter_mut_sig_norm_hrd(sbs_sigs,hrd_scores,1000)
sbs_filt_norm_1500_hrd <- filter_mut_sig_norm_hrd(sbs_sigs,hrd_scores,1500)
id_filt_norm_hrd <- filter_mut_sig_norm_hrd(id_sigs,hrd_scores,50)
#
#sbs_filt_500$names <- row.names(sbs_filt_500)
#id_filt$names <- row.names(id_filt)
id_filt_merge <- id_filt[row.names(id_filt) %in% row.names(sbs_filt_500),]
sbs_filt_merge <- sbs_filt_500[row.names(sbs_filt_500) %in% row.names(id_filt_merge),]
hrd_filt_merge <- hrd_scores[row.names(hrd_scores) %in% row.names(sbs_filt_merge),]
# subset what we need
hrd_filt_merge <- hrd_filt_merge[1:(length(hrd_filt_merge)-5)]
#id_filt_merge <- id_filt_merge[1:(length(id_filt_merge)-3)]
sbs_filt_merge <- sbs_filt_merge[1:(length(sbs_filt_merge)-3)]
# lets sort everything
hrd_filt_merge <- hrd_filt_merge[order(row.names(hrd_filt_merge)),]
sbs_filt_merge <- sbs_filt_merge[order(row.names(sbs_filt_merge)),]
id_filt_merge <- id_filt_merge[order(row.names(id_filt_merge)),]
#
id_sbs_filt_500_merge <- cbind(sbs_filt_merge,id_filt_merge)
id_sbs_hrd_filt_500_merge <- cbind(sbs_filt_merge,id_filt_merge,hrd_filt_merge)
# Normalized
id_filt_norm_merge <- id_filt_norm[row.names(id_filt_norm) %in% row.names(sbs_filt_norm_500),]
sbs_filt_norm_merge <- sbs_filt_norm_500[row.names(sbs_filt_norm_500) %in% row.names(id_filt_norm_merge),]
hrd_filt_norm_merge <- hrd_scores[row.names(hrd_scores) %in% row.names(sbs_filt_norm_merge),]
# subset what we need
hrd_filt_norm_merge <- hrd_filt_norm_merge[1:(length(hrd_filt_norm_merge)-5)]
#id_filt_norm_merge <- id_filt_norm_merge[1:(length(id_filt_norm_merge)-3)]
sbs_filt_norm_merge <- sbs_filt_norm_merge[1:(length(sbs_filt_norm_merge)-3)]
# lets sort everything
hrd_filt_norm_merge <- hrd_filt_norm_merge[order(row.names(hrd_filt_norm_merge)),]
sbs_filt_norm_merge <- sbs_filt_norm_merge[order(row.names(sbs_filt_norm_merge)),]
id_filt_norm_merge <- id_filt_norm_merge[order(row.names(id_filt_norm_merge)),]
#
id_sbs_filt_norm_500_merge <- cbind(sbs_filt_norm_merge,id_filt_norm_merge)
id_sbs_hrd_filt_norm_500_merge <- cbind(sbs_filt_norm_merge,id_filt_norm_merge,hrd_filt_norm_merge)
# create our lda dataset
lda_dat <- id_sbs_hrd_filt_norm_500_merge
lda_dat$m_count <- NULL
lda_dat$group <- NULL
# create our hrd groups based on top 25 percentile of HRD scores
lda_dat$group <- as.factor(ifelse(lda_dat$HRD > 26,"high","low"))
# create our testing and training dataset
set.seed(123)
ind <- sample(2, nrow(lda_dat),
replace = TRUE,
prob = c(0.6, 0.4))
training <- lda_dat[ind==1,]
testing <- lda_dat[ind==2,]
# perform the lda
linear <- lda(group~., training)
linear
# apply prediction
p <- predict(linear, training)
ldahist(data = p$x[,1], g = training$group)
#ldahist(data = p$x[,2], g = training$group)
# bi plot
ggord(linear, training$group, ylim = c(-10, 10))
full.model <- lm(group ~ data= lda_dat)
full.model <- lm(group ~ data = lda_dat)
# create our lda dataset
lda_dat <- id_sbs_hrd_filt_norm_500_merge
lda_dat$m_count <- NULL
lda_dat$group <- NULL
# create our hrd groups based on top 25 percentile of HRD scores
lda_dat$group <- as.factor(ifelse(lda_dat$HRD > 26,"high","low"))
# create our testing and training dataset
set.seed(123)
ind <- sample(2, nrow(lda_dat),
replace = TRUE,
prob = c(0.6, 0.4))
training <- lda_dat[ind==1======
# create our lda dataset
lda_dat <- id_sbs_hrd_filt_norm_500_merge
lda_dat$m_count <- NULL
lda_dat$group <- NULL
# create our hrd groups based on top 25 percentile of HRD scores
lda_dat$group <- as.factor(ifelse(lda_dat$HRD > 26,"high","low"))
# create our testing and training dataset
set.seed(123)
ind <- sample(2, nrow(lda_dat),
replace = TRUE,
prob = c(0.6, 0.4))
training <- lda_dat[ind==1,]
testing <- lda_dat[ind==2,]
# get the full model
full.model <- lm(group ~ .lda_dat,data = lda_dat)
full.model <- lm(group ~ .,data = lda_dat)
View(lda_dat)
library(devtools)
devtools::install_github("KlugerLab/DAseq")
quit()
BiocManager::install("GSEABase")
quit()
BiocManager::install("GSEABase")
library(devtools)
devtools::install_github("FunGeST/Palimpsest")
library(Palimpsest)
install.packages("bedr")
quit()
library(dplyr)
library(tibble)
library(ggplot2)
library(ggfortify)
library(gridExtra)
library(reshape)
library(pheatmap)
# loading libraries for mutational patterns and BSgenome
library(MutationalPatterns)
library(BSgenome)
library(BSgenome.Hsapiens.UCSC.hg19)
ref_genome <- "BSgenome.Hsapiens.UCSC.hg19"
# loading in some other packages for inspecting the datasets
library(lsa)
# loading in UMAP
library(umap)
hrd_scores <- read.table(file = "Z:/ResearchHome/Groups/shelagrp/projects/HRD/common/CSTN/HRD/WES/all_hrd_final_result.txt",header = TRUE,row.names = 1)
quit()
directory <- (file.path("example_dataset"))
#SMD read-in
tcga_data<-read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples.txt", sep = ''))), sep="\t", header=TRUE)
sbs_score<-read.table(file.path((paste(directory, "/TCGA_SBS_signature_exposure.txt", sep = ''))), sep="\t", header=TRUE)
id_score<-read.table(file.path((paste(directory, "/TCGA_ID_signature_exposures.txt", sep = ''))), sep="\t", header=TRUE)
gene_loh<-read.table(file.path((paste(directory, "/gene_LOH_events.txt", sep = ''))), sep="\t", header=TRUE)
#EVAN read-in
clinical_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples_mut_calls.txt", sep = ''))), sep="\t", header=TRUE)
hrd_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples.txt", sep = ''))), sep="\t", header=TRUE)
id_data<- read.table(file.path((paste(directory, "/TCGA_ID_signature_exposures.txt", sep = ''))), sep="\t", header=TRUE)
sbs_data <- read.table(file.path((paste(directory, "/TCGA_SBS_signature_exposure.txt", sep = ''))), sep="\t", header=TRUE)
mut_call_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples_mut_calls.txt", sep = ''))), sep="\t", header=TRUE)
setwd("C:/Users/esavage/Desktop/HEARD/HEARD/HEARD")
#load example dataset first
directory <- (file.path("example_dataset"))
#SMD read-in
tcga_data<-read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples.txt", sep = ''))), sep="\t", header=TRUE)
sbs_score<-read.table(file.path((paste(directory, "/TCGA_SBS_signature_exposure.txt", sep = ''))), sep="\t", header=TRUE)
id_score<-read.table(file.path((paste(directory, "/TCGA_ID_signature_exposures.txt", sep = ''))), sep="\t", header=TRUE)
gene_loh<-read.table(file.path((paste(directory, "/gene_LOH_events.txt", sep = ''))), sep="\t", header=TRUE)
#EVAN read-in
clinical_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples_mut_calls.txt", sep = ''))), sep="\t", header=TRUE)
hrd_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples.txt", sep = ''))), sep="\t", header=TRUE)
id_data<- read.table(file.path((paste(directory, "/TCGA_ID_signature_exposures.txt", sep = ''))), sep="\t", header=TRUE)
sbs_data <- read.table(file.path((paste(directory, "/TCGA_SBS_signature_exposure.txt", sep = ''))), sep="\t", header=TRUE)
mut_call_data <- read.table(file.path((paste(directory, "/TCGA_HRD_positive_samples_mut_calls.txt", sep = ''))), sep="\t", header=TRUE)
View(clinical_data)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
